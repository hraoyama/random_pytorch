{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"collab_xnn_2ndRun_test13.ipynb","provenance":[],"collapsed_sections":["av22_gwc_hOd","UrA1SY4CHTOS"],"machine_shape":"hm","authorship_tag":"ABX9TyPJ1dfuzJh920gvL8kFo2IA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"av22_gwc_hOd"},"source":["# Setup and install for Test13"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l247Lv_MYR8O","executionInfo":{"status":"ok","timestamp":1638745721566,"user_tz":0,"elapsed":20221,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}},"outputId":"4bd44c21-1df8-43c1-979f-c011609365b2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"yqquQY0B65AH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638745727949,"user_tz":0,"elapsed":6387,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}},"outputId":"d270dcdf-a7aa-4789-d7cb-bb4177056e6b"},"source":["%pip install gpflow\n","%pip install plotnine"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gpflow\n","  Downloading gpflow-2.3.0-py3-none-any.whl (286 kB)\n","\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20 kB 41.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30 kB 46.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 71 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 92 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 102 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 112 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 122 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 133 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 153 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 163 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 174 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 184 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 194 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 204 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 215 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 225 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 235 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 245 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 256 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 266 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 276 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286 kB 14.6 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-probability>0.10.0 in /usr/local/lib/python3.7/dist-packages (from gpflow) (0.15.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from gpflow) (57.4.0)\n","Collecting dataclasses\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from gpflow) (2.7.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gpflow) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpflow) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from gpflow) (3.10.0.2)\n","Collecting multipledispatch>=0.6\n","  Downloading multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n","Collecting deprecated\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gpflow) (21.3)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from gpflow) (0.8.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from multipledispatch>=0.6->gpflow) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.42.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (3.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.6.3)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (2.7.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (12.0.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (0.37.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (1.13.3)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (0.12.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (2.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (0.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (2.7.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (0.22.0)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (2.7.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gpflow) (3.17.3)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.2.0->gpflow) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (1.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (1.35.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (0.4.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.2.0->gpflow) (3.1.1)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>0.10.0->gpflow) (1.3.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>0.10.0->gpflow) (4.4.2)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>0.10.0->gpflow) (0.1.6)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gpflow) (3.0.6)\n","Installing collected packages: multipledispatch, deprecated, dataclasses, gpflow\n","Successfully installed dataclasses-0.6 deprecated-1.2.13 gpflow-2.3.0 multipledispatch-0.6.0\n","Requirement already satisfied: plotnine in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.19.5)\n","Requirement already satisfied: mizani>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.6.0)\n","Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.5.2)\n","Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.1.0)\n","Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.1.5)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (0.10.2)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from plotnine) (1.4.1)\n","Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from plotnine) (3.2.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (3.0.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.1->plotnine) (2.8.2)\n","Requirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from mizani>=0.6.0->plotnine) (3.3.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->plotnine) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.1->plotnine) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0BjPTJxxk0YK","executionInfo":{"status":"ok","timestamp":1638745737424,"user_tz":0,"elapsed":9477,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}},"outputId":"8cdb8435-17d3-4b67-f00c-6e13c0972cdb"},"source":["%pip install keras_self_attention\n","%pip install keras-tuner\n","%pip install pycm"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting keras_self_attention\n","  Downloading keras-self-attention-0.50.0.tar.gz (12 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (1.19.5)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (2.7.0)\n","Building wheels for collected packages: keras-self-attention\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.50.0-py3-none-any.whl size=19414 sha256=02bf7b5bfb7794c667286b6511891afa650579d7a04122e5841354de3c1942e2\n","  Stored in directory: /root/.cache/pip/wheels/92/7a/a3/231bef5803298e7ec1815215bc0613239cb1e9c03c57b13c14\n","Successfully built keras-self-attention\n","Installing collected packages: keras-self-attention\n","Successfully installed keras-self-attention-0.50.0\n","Collecting keras-tuner\n","  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n","\u001b[K     |████████████████████████████████| 98 kB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n","Collecting kt-legacy\n","  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.7.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.6)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.42.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n","Installing collected packages: kt-legacy, keras-tuner\n","Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n","Collecting pycm\n","  Downloading pycm-3.3-py2.py3-none-any.whl (65 kB)\n","\u001b[K     |████████████████████████████████| 65 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pycm) (1.19.5)\n","Collecting art>=1.8\n","  Downloading art-5.3-py2.py3-none-any.whl (574 kB)\n","\u001b[K     |████████████████████████████████| 574 kB 28.0 MB/s \n","\u001b[?25hInstalling collected packages: art, pycm\n","Successfully installed art-5.3 pycm-3.3\n"]}]},{"cell_type":"code","metadata":{"id":"EfIU_eNp3Zio","executionInfo":{"status":"ok","timestamp":1638745739220,"user_tz":0,"elapsed":1799,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["from plotnine import *\n","from plotnine.themes import *"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZmUjYbArAuQT","executionInfo":{"status":"ok","timestamp":1638745741787,"user_tz":0,"elapsed":2570,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["import tensorflow as tf\n","from scipy.io import loadmat\n","import random\n","import math\n","import tensorflow_probability as tfp"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fg0OYkHWkvbj","executionInfo":{"status":"ok","timestamp":1638745741788,"user_tz":0,"elapsed":7,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.layers import  Dense, Flatten, Activation, Dropout, Embedding, Conv1D, MaxPooling1D, GRU\n","from tensorflow.keras.layers import LSTM, TimeDistributed, Permute,Reshape, Lambda, RepeatVector, Input,Multiply\n","from tensorflow.keras.layers import  Dense, Flatten, Activation, Dropout, Embedding, Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, Concatenate, BatchNormalization, GaussianNoise\n","from tensorflow.keras.layers import SimpleRNN, GRU, LeakyReLU\n","from tensorflow.keras.layers import Concatenate, Average \n","from tensorflow.keras.models import Sequential, load_model, Model\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import  Bidirectional\n","from timeit import default_timer as timer\n","import h5py as h5\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model\n","import errno\n","from tensorflow.keras.applications.imagenet_utils import decode_predictions\n","import random\n","import warnings\n","import gpflow\n","from gpflow.utilities import ops, print_summary, set_trainable\n","from gpflow.config import set_default_float, default_float, set_default_summary_fmt\n","from gpflow.ci_utils import ci_niter\n","import warnings\n","from functools import partial\n","from multiprocessing import Pool, cpu_count\n","from tensorflow.keras.layers import  Dense, Flatten, Activation, Dropout, Embedding, Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, Concatenate, BatchNormalization, GaussianNoise\n","from tensorflow.keras.layers import LSTM, TimeDistributed, Permute, Reshape, Lambda, RepeatVector, Input, Multiply, SimpleRNN, GRU, LeakyReLU\n","from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n","from tensorflow.keras import regularizers\n","import os\n","from collections import defaultdict\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","import keras_tuner as kt"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PieVKPfHHYQ6"},"source":["_paper_name_ establishes the reusable name of the paper, it represents the directory under data_papers on the google drive"]},{"cell_type":"code","metadata":{"id":"BI4p7ZKb0Qz2","executionInfo":{"status":"ok","timestamp":1638745741789,"user_tz":0,"elapsed":7,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["paper_name = \"test13\""],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"433z6V3T2rB2","executionInfo":{"status":"ok","timestamp":1638745743019,"user_tz":0,"elapsed":1236,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["import os, sys\n","import errno\n","\n","# make a directory if it does not exist\n","def make_dir_if_not_exist(used_path):\n","    if not os.path.isdir(used_path):\n","        try:\n","            os.mkdir(used_path)\n","        except OSError as exc:\n","            if exc.errno != errno.EEXIST:\n","                raise exc\n","            else:\n","                raise ValueError(f'{used_path} directoy cannot be created because its parent directory does not exist.')\n","\n","# make directories if they do not exist\n","\n","make_dir_if_not_exist(\"/content/drive/MyDrive/data_papers/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_features/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_history/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/gp_collab/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_predictions/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_ccs/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_tb/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/summary_results/\")\n","make_dir_if_not_exist(f\"/content/drive/MyDrive/data_papers/{paper_name}/summary_results/temp/\")"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IufmBnPeB50P"},"source":["\n","This will use the Test13 dataset\n","\n","* A. Fiannaca, M. La Rosa, L. La Paglia, R. Rizzo, and A. Urso. Nrc: Non-coding rna classifier based on structural features. BioData Mining, 10, 08 2017. doi: 10.1186/s13040-017-0148-2.\n","\n","The orginal loading of the data is from : e2e_dataprocess_from_fasta_example.ipynb\n","\n"]},{"cell_type":"code","metadata":{"id":"0yCKQpti4HWJ","executionInfo":{"status":"ok","timestamp":1638745743019,"user_tz":0,"elapsed":3,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["data_location = f'/content/drive/MyDrive/data_papers/{paper_name}'"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7--mKqbEhZZ","executionInfo":{"status":"ok","timestamp":1638745747193,"user_tz":0,"elapsed":4176,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["# Run this cell to load the dataset\n","INPUT_DIM = 8    # \n","\n","hf_Train = h5.File(f'{data_location}/Fold_10_Train_Data_1000.h5', 'r')\n","hf_Test = h5.File(f'{data_location}/Fold_10_Test_Data_1000.h5', 'r')\n","\n","X_train = hf_Train['Train_Data'] # Get train set\n","X_train = np.array(X_train)\n","Y_train = hf_Train['Label']      # Get train label\n","Y_train = np.array(Y_train)\n","\n","X_test = hf_Test['Train_Data']     # Get test set\n","X_test = np.array(X_test)\n","Y_test = hf_Test['Label']       # Get test label\n","Y_test = np.array(Y_test)\n","\n","Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n","Y_test = to_categorical(Y_test, 13)    #  Process the label of te\n","\n","def coShuffled_vectors(X,Y):\n","    if tf.shape(X)[0] ==  tf.shape(Y)[0]:\n","        test_idxs = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32)\n","        shuffled_test_idxs = tf.random.shuffle(test_idxs)\n","        return ( tf.gather(X, shuffled_test_idxs), tf.gather(Y, shuffled_test_idxs) )\n","    else:\n","        raise ValueError(f\"0-dimension has to be the same {tf.shape(X)[0]} != {tf.shape(Y)[0]}\")\n","\n","X_test_shuffled, Y_test_shuffled = coShuffled_vectors(np.array(hf_Test['Train_Data']), to_categorical(np.array(hf_Test['Label']),13))\n","X_train_shuffled, Y_train_shuffled = coShuffled_vectors(np.array(hf_Train['Train_Data']), to_categorical(np.array(hf_Train['Label']),13))\n","\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"6b7tNfakowYM","executionInfo":{"status":"ok","timestamp":1638745747194,"user_tz":0,"elapsed":4,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["def plot_history(history):\n","    acc_keys = [k for k in history.history.keys() if k in ('accuracy', 'val_accuracy')] \n","    loss_keys = [k for k in history.history.keys() if not k in acc_keys]\n","    for k, v in history.history.items():\n","        if k in acc_keys:\n","            plt.figure(1)\n","            plt.plot(v)\n","        else:\n","            plt.figure(2)\n","            plt.plot(v)\n","    plt.figure(1)\n","    plt.title('Accuracy vs. epochs')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(acc_keys, loc='upper right')\n","    plt.figure(2)\n","    plt.title('Loss vs. epochs')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(loss_keys, loc='upper right')\n","    plt.show()\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5hVSGiwo3t_","executionInfo":{"status":"ok","timestamp":1638745747586,"user_tz":0,"elapsed":396,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["\n","def get_layer_by_name(layers, name, return_first = True):\n","    matching_named_layers = [ l for l in layers if l.name==name]\n","    if not matching_named_layers:\n","        return None\n","    return matching_named_layers[0] if return_first else matching_named_layers\n","\n","\n","def get_combined_features_from_models(\n","        to_combine, \n","        X_train, Y_train, \n","        X_test, Y_test,\n","        reverse_one_hot = False,\n","        normalize_X_func = None):\n","    \n","    models = dict()\n","    X_trains_out = []\n","    X_test_out = []\n","    XY_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: None))))\n","    \n","    if reverse_one_hot:\n","        Y_train_new = np.apply_along_axis(np.argmax, 1, Y_train) + 1  \n","        Y_test_new = np.apply_along_axis(np.argmax, 1, Y_test) + 1 \n","    else:\n","        Y_train_new = Y_train.copy()\n","        Y_test_new = Y_test.copy()\n","    \n","    for model_file_name, layer_name, kwargs in to_combine:\n","        model_here = None\n","        if isinstance(model_file_name, tf.keras.models.Model):\n","            model_here = model_file_name\n","            model_file_name = model_here.name\n","        else:\n","            if model_file_name in models.keys():\n","                model_here = models[model_file_name]\n","            else:\n","                model_here = tf.keras.models.load_model(model_file_name, **kwargs) if kwargs is not None else tf.keras.models.load_model(model_file_name)\n","        features_model = Model(model_here.input, \n","                               get_layer_by_name(model_here.layers,layer_name).output)\n","        if normalize_X_func is None:\n","            X_trains_out.append(np.array(features_model.predict(X_train), dtype='float64'))\n","            X_test_out.append(np.array(features_model.predict(X_test), dtype='float64'))\n","        else:\n","            X_trains_out.append(np.array(normalize_X_func(features_model.predict(X_train)), dtype='float64'))\n","            X_test_out.append(np.array(normalize_X_func(features_model.predict(X_test)), dtype='float64'))\n","        XY_dict[model_file_name][layer_name]['Train']['X'] = X_trains_out[-1]\n","        XY_dict[model_file_name][layer_name]['Test']['X'] = X_test_out[-1]\n","        XY_dict[model_file_name][layer_name]['Train']['Y'] = Y_train_new\n","        XY_dict[model_file_name][layer_name]['Test']['Y'] = Y_test_new\n","        models[model_file_name] = model_here            \n","        \n","    X_train_new = np.concatenate(tuple(X_trains_out), axis = 1)\n","    X_test_new = np.concatenate(tuple(X_test_out), axis = 1)\n","    \n","    data_train = (X_train_new, Y_train_new)\n","    data_test = (X_test_new, Y_test_new)    \n","    \n","        \n","    return (models, data_train, data_test,XY_dict)\n","\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"OyVEfMk4pDEa","executionInfo":{"status":"ok","timestamp":1638745747587,"user_tz":0,"elapsed":12,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["def run_and_save_model(model_func, X_train, Y_train, kwargs):    \n","    m = model_func()\n","    m.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n","    history = m.fit(X_train, Y_train, **kwargs) \n","    m.save(f\"{m.name}_Tenth_Fold_New_Model_500_8\") #Save the model\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxNjkxgjxc5y","executionInfo":{"status":"ok","timestamp":1638745747587,"user_tz":0,"elapsed":11,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}},"outputId":"909841bb-c50f-403e-ac63-9f419ef2744f"},"source":["import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","import h5py as h5\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Conv1D, LeakyReLU, MaxPooling1D, BatchNormalization, GaussianNoise, Dropout, Dense, Flatten\n","import errno\n","import os\n","from collections import defaultdict\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from tensorflow.summary import create_file_writer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import kerastuner as kt\n","from kerastuner import HyperModel\n","import numpy as np\n","import itertools\n","import multiprocessing\n","from numpy import genfromtxt\n","import seaborn as sns\n","from sklearn.metrics import precision_recall_fscore_support\n","from pycm import ConfusionMatrix"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n","  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"aWfKrF40X4gX","executionInfo":{"status":"ok","timestamp":1638745747587,"user_tz":0,"elapsed":10,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}},"outputId":"cd45482d-d36c-43b4-9ce2-1cb559af0117"},"source":["data_location"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/data_papers/test13'"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"87ma654Ixu3f","executionInfo":{"status":"ok","timestamp":1638745747588,"user_tz":0,"elapsed":10,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["\n","def coShuffled_vectors(X, Y):\n","    if tf.shape(X)[0] == tf.shape(Y)[0]:\n","        test_idxs = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32)\n","        shuffled_test_idxs = tf.random.shuffle(test_idxs)\n","        return (tf.gather(X, shuffled_test_idxs), tf.gather(Y, shuffled_test_idxs))\n","    else:\n","        raise ValueError(f\"0-dimension has to be the same {tf.shape(X)[0]} != {tf.shape(Y)[0]}\")\n","\n","def reverse_one_hot(Y_input):\n","    return np.apply_along_axis(np.argmax, 1, Y_input) + 1\n","\n","def getNpArrayFromH5(hf_Data):\n","    X_train = hf_Data['Train_Data']  # Get train set\n","    X_train = np.array(X_train)\n","    Y_train = hf_Data['Label']  # Get train label\n","    Y_train = np.array(Y_train)\n","    return X_train, Y_train\n","\n","def get_confusion_matrix_classification(model, X, Y_true):\n","    y_pred = model.predict(X)\n","    y_true = np.apply_along_axis(np.argmax, 1, Y_true)\n","    y_pred = np.apply_along_axis(np.argmax, 1, y_pred)\n","    return (confusion_matrix(y_true, y_pred), y_pred, y_true)\n","\n","def misclass_perc_to_weight(input_confusion, add_base=True, func=None):\n","    perc_misclassified = 1.0 - np.array([ input_confusion[x,x] for x in np.arange(input_confusion.shape[0]).tolist() ])/input_confusion.sum(axis=1)\n","    \n","    base_val = min(perc_misclassified[perc_misclassified>0.0])\n","    if add_base:        \n","        perc_misclassified = perc_misclassified + base_val\n","    \n","    perc_misclassified = [ x/base_val for x in perc_misclassified]\n","    return dict([ (idx, func(perc_val)) if func is not None else (idx, perc_val) for idx, perc_val in enumerate(perc_misclassified) ])\n","\n","def prf(model,xtest, ytest):\n","  y_pred = np.apply_along_axis(np.argmax, 1, model.predict(xtest))\n","  y_true = np.apply_along_axis(np.argmax, 1, ytest)\n","  return precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n","\n","def get_sp_pr_rc_f1(model,xtest, ytest):  \n","    y_pred = np.apply_along_axis(np.argmax, 1, model.predict(xtest))\n","    y_true = np.apply_along_axis(np.argmax, 1, ytest)\n","    cmres = ConfusionMatrix(actual_vector=y_true,predict_vector=y_pred)\n","    pr, rc, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")   \n","    return cmres.TNR_Macro, pr, rc, f1\n"," \n","def get_sp_pr_rc_f1_acc(model,xtest, ytest):  \n","    spec, pr, rc, f1 = get_sp_pr_rc_f1(model,xtest, ytest)\n","    acc = model.evaluate(xtest,ytest)[-1]        \n","    return spec, pr, rc, f1, acc\n","\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dd-0iNNhk3t","executionInfo":{"status":"ok","timestamp":1638745747588,"user_tz":0,"elapsed":10,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["def plot_history(history):\n","    acc_keys = [k for k in history.history.keys() if k in ('accuracy', 'val_accuracy')]\n","    loss_keys = [k for k in history.history.keys() if not k in acc_keys]\n","    for k, v in history.history.items():\n","        if k in acc_keys:\n","            plt.figure(1)\n","            plt.plot(v)\n","        else:\n","            plt.figure(2)\n","            plt.plot(v)\n","    plt.figure(1)\n","    plt.title('Accuracy vs. epochs')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(acc_keys, loc='lower right')\n","    plt.figure(2)\n","    plt.title('Loss vs. epochs')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(loss_keys, loc='upper right')\n","    plt.show()\n","\n","\n","def get_layer_by_name(layers, name, return_first=True):\n","    matching_named_layers = [l for l in layers if l.name == name]\n","    if not matching_named_layers:\n","        return None\n","    return matching_named_layers[0] if return_first else matching_named_layers\n","\n","\n","def make_dir_if_not_exist(used_path):\n","    if not os.path.isdir(used_path):\n","        try:\n","            os.mkdir(used_path)\n","        except OSError as exc:\n","            if exc.errno != errno.EEXIST:\n","                raise exc\n","            else:\n","                raise ValueError(f'{used_path} directoy cannot be created because its parent directory does not exist.')\n","\n","\n","def source_model(model_func, model_name, input_shape):\n","    m = None\n","    if isinstance(model_func, tf.keras.models.Model):\n","        m = model_func\n","        m._name = model_name\n","    else:\n","        m = model_func(model_name, input_shape)\n","    return m\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTv646yChscq","executionInfo":{"status":"ok","timestamp":1638745747857,"user_tz":0,"elapsed":279,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["\n","\n","def compile_and_fit_model_with_tb(model_func,\n","                                  model_name,\n","                                  input_shape,\n","                                  X_train,\n","                                  Y_train,\n","                                  save_every_epoch=True,\n","                                  save_final=False,\n","                                  **kwargs):\n","    m = None\n","    if isinstance(model_func, tf.keras.models.Model):\n","        m = model_func\n","        m._name = model_name\n","    else:\n","        m = model_func(model_name, input_shape)\n","    tb_callback = TensorBoard(log_dir=f'{m.name}_logs', histogram_freq=kwargs.pop(\"histogram_freq\", 1))\n","    if save_every_epoch:\n","        tb_callback.append(ModelCheckpoint(f'{m.name}' + '_model_{epoch:03d}_{val_accuracy:0.2f}'))\n","    m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    history = m.fit(X_train, Y_train, callbacks=[tb_callback], verbose=2, **kwargs)\n","    if save_final:\n","        make_dir_if_not_exist(model_name)\n","        m.save(f\"{m.name}_saved_model_after_fit\")  # Save the model\n","    return (m, history)\n","    # m.save(f\"{m.name}_Tenth_Fold_New_Model_500_8\") #Save the model\n","\n","\n","def compile_model_and_fit_with_custom_loop(model_func,\n","                                           model_name,\n","                                           input_shape,\n","                                           X_train,\n","                                           Y_train,\n","                                           **kwargs):\n","    make_dir_if_not_exist(model_name)\n","    m = None\n","    if isinstance(model_func, tf.keras.models.Model):\n","        m = model_func\n","        m._name = model_name\n","    else:\n","        m = model_func(model_name, input_shape)\n","\n","    train_writer = create_file_writer(f'{m.name}_logs/train/')\n","    test_writer = create_file_writer(f'{m.name}_logs/test/')\n","    train_step = test_step = 0\n","\n","    acc_metric = tf.keras.metrics.CategoricalAccuracy()\n","    optimizer = tf.keras.optimizers.Adam()\n","    num_epochs = kwargs.get(\"epochs\", 10)\n","\n","    AUTOTUNE = tf.data.experimental.AUTOTUNE\n","    BATCH_SIZE = kwargs.get(\"batch_size\", 32)\n","    X_test, Y_test = kwargs.get(\"validation_data\", (None, None))\n","    if X_test is None:\n","        raise ValueError(\"Missing X validation data\")\n","    if Y_test is None:\n","        raise ValueError(\"Missing Y validation data\")\n","\n","    train_dataset_tf = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n","    train_dataset_tf = train_dataset_tf.batch(BATCH_SIZE)\n","    train_dataset_tf = train_dataset_tf.prefetch(AUTOTUNE)\n","\n","    test_dataset_tf = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n","    test_dataset_tf = train_dataset_tf.batch(BATCH_SIZE)\n","    test_dataset_tf = train_dataset_tf.prefetch(AUTOTUNE)\n","\n","    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n","\n","    for epoch in range(num_epochs):\n","        # Iterate through training set\n","        for batch_idx, (x, y) in enumerate(train_dataset_tf):\n","            with tf.GradientTape() as tape:\n","                y_pred = m(x, training=True)\n","                loss = loss_fn(y, y_pred)\n","\n","            gradients = tape.gradient(loss, m.trainable_weights)\n","            optimizer.apply_gradients(zip(gradients, m.trainable_weights))\n","            acc_metric.update_state(y, y_pred)\n","\n","            with train_writer.as_default():\n","                tf.summary.scalar(\"Loss\", loss, step=train_step)\n","                tf.summary.scalar(\n","                    \"Accuracy\", acc_metric.result(), step=train_step,\n","                )\n","                train_step += 1\n","        # Reset accuracy in between epochs (and for testing and test)\n","        acc_metric.reset_states()\n","        # Iterate through test set\n","        for batch_idx, (x, y) in enumerate(test_dataset_tf):\n","            y_pred = m(x, training=False)\n","            loss = loss_fn(y, y_pred)\n","            acc_metric.update_state(y, y_pred)\n","            with test_writer.as_default():\n","                tf.summary.scalar(\"Loss\", loss, step=test_step)\n","                tf.summary.scalar(\n","                    \"Accuracy\", acc_metric.result(), step=test_step,\n","                )\n","                test_step += 1\n","\n","        acc_metric.reset_states()  # Reset accuracy in between epochs (and for testing and test)\n","\n","    return m\n","\n","\n","\n","def run_mirrored_strategy(model_func, base_batch_size, nepochs, x_train, y_train, x_test, y_test, **kwargs):\n","    strategy = tf.distribute.MirroredStrategy()\n","    with strategy.scope():\n","        model = model_func()\n","        model.compile(\n","            optimizer=tf.keras.optimizers.Adam(),\n","            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","            metrics=tf.keras.metrics.SparseCategoricalAccuracy()\n","        )\n","    batch_size_mirr_strat = base_batch_size * strategy.num_replicas_in_sync\n","    history = model.fit(x_train, y_train, epochs=nepochs, batch_size=batch_size_mirr_strat,\n","                        validation_data=(x_test, y_test),\n","                        **kwargs)\n","    return model, history\n","\n","\n","def sparse_setdiff(a1, a2):\n","    a1a = a1.reshape(a1.shape[0], -1)\n","    a2a = a2.reshape(a2.shape[0], -1)\n","    spa2a = [np.where(x)[0].tolist() for x in a2a]\n","    spa1a = [np.where(x)[0].tolist() for x in a1a]\n","    idxs_to_keep = []\n","    for idx, sample in enumerate(spa1a):\n","        try:\n","            spa2a.index(sample)\n","        except ValueError:\n","            # not in list\n","            idxs_to_keep.append(idx)\n","    return a1[idxs_to_keep], idxs_to_keep\n","\n","\n","\n","def reinitialize_weights(model):\n","    for ix, layer in enumerate(model.layers):\n","        if hasattr(model.layers[ix], 'kernel_initializer') and hasattr(model.layers[ix], 'bias_initializer'):\n","            weight_initializer = model.layers[ix].kernel_initializer\n","            bias_initializer = model.layers[ix].bias_initializer\n","    \n","            old_weights, old_biases = model.layers[ix].get_weights()\n","    \n","            model.layers[ix].set_weights([\n","                weight_initializer(shape=old_weights.shape),\n","                bias_initializer(shape=len(old_biases))])            \n","    return model\n","\n","def reverse_tensor(X):\n","    return tf.gather(X, tf.reverse(tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32),(0,)) )\n","\n","def get_combined_features_from_models(\n","    \n","        to_combine,\n","        X_train, Y_train,\n","        X_test, Y_test,\n","        reverse_one_hot=False,\n","        normalize_X_func=None):\n","    \n","    models = []\n","    models_dict = {}\n","    X_trains_out = []\n","    X_test_out = []\n","    XY_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: None))))\n","\n","    models_have_different_inputs = isinstance(Y_train,list)\n","\n","    if reverse_one_hot:\n","        if models_have_different_inputs:\n","            Y_train_new = np.apply_along_axis(np.argmax, 1, Y_train) + 1\n","            Y_test_new = np.apply_along_axis(np.argmax, 1, Y_test) + 1\n","        else:\n","            Y_train_new = [ np.apply_along_axis(np.argmax, 1, y_train) + 1 for y_train in Y_train ]  \n","            Y_test_new = [ np.apply_along_axis(np.argmax, 1, y_test) + 1 for y_test in Y_test ]              \n","    else:\n","        if models_have_different_inputs:\n","            Y_train_new = Y_train.copy()\n","            Y_test_new = Y_test.copy()\n","        else:\n","            Y_train_new = [ y_train.copy() for y_train in Y_train ] \n","            Y_test_new = [ y_test.copy() for y_test in Y_train ] \n","            \n","\n","    extraction_counter =0\n","    for model_file_name, layer_name, kwargs in to_combine:\n","        model_here = None\n","        if isinstance(model_file_name, tf.keras.models.Model):\n","            model_here = model_file_name\n","            model_file_name = model_here.name\n","        else:\n","            if model_file_name in models_dict.keys():\n","                model_here = models_dict[model_file_name]\n","            else:\n","                model_here = tf.keras.models.load_model(model_file_name,\n","                                                        **kwargs) if kwargs is not None else tf.keras.models.load_model \\\n","                    (model_file_name)\n","\n","        features_model = Model(model_here.input,\n","                               get_layer_by_name(model_here.layers, layer_name).output)\n","        \n","        if normalize_X_func is None:\n","            X_trains_out.append(np.array(features_model.predict(X_train if not models_have_different_inputs else X_train[extraction_counter]), dtype='float64'))\n","            X_test_out.append(np.array(features_model.predict(X_test if not models_have_different_inputs else X_test[extraction_counter]), dtype='float64'))\n","        else:\n","            X_trains_out.append(np.array(normalize_X_func(features_model.predict(X_train if not models_have_different_inputs else X_train[extraction_counter])), dtype='float64'))\n","            X_test_out.append(np.array(normalize_X_func(features_model.predict(X_test if not models_have_different_inputs else X_test[extraction_counter])), dtype='float64'))\n","        XY_dict[model_file_name][layer_name]['Train']['X'] = X_trains_out[-1]\n","        XY_dict[model_file_name][layer_name]['Test']['X'] = X_test_out[-1]\n","        XY_dict[model_file_name][layer_name]['Train']['Y'] = Y_train_new\n","        XY_dict[model_file_name][layer_name]['Test']['Y'] = Y_test_new\n","        models.append(((model_file_name, layer_name), (model_here, features_model)))\n","        models_dict[model_file_name] = model_here\n","        extraction_counter += 1\n","\n","    X_train_new = np.concatenate(tuple(X_trains_out), axis=1)\n","    X_test_new = np.concatenate(tuple(X_test_out), axis=1)\n","\n","    data_train = (X_train_new, Y_train_new)\n","    data_test = (X_test_new, Y_test_new)\n","\n","    return models, data_train, data_test, XY_dict\n","\n","class SaveBestOverCombinedThresholds(tf.keras.callbacks.Callback):\n","\n","    def __init__(self, colab_download = False, observed_values = [ ('accuracy',0.9) ] ):\n","        self.thresholds = dict(observed_values)\n","        self.last_best_values = dict([ (obs_name, np.nan) for obs_name in self.thresholds.keys()] )\n","        self.colab_download = colab_download\n","        \n","    def on_epoch_end(self, epoch, logs=None):        \n","        register = None\n","        for k,v in self.thresholds.items():\n","            if k not in logs.keys():\n","                raise ValueError(f\"{k} not found in logs\")\n","            passes_threshold = logs[k] > self.thresholds[k]                 \n","            register = passes_threshold if register is None else (register and passes_threshold)\n","        \n","        if register:\n","            for k,v in self.thresholds.items():\n","                if np.isnan(self.last_best_values[k]):\n","                    self.last_best_values[k] = logs[k]\n","                else:\n","                    if logs[k] < self.last_best_values[k]:\n","                        register = False\n","                        break\n","            if register:\n","                for k,v in self.thresholds.items():\n","                    self.last_best_values[k] = logs[k]\n","                base_name = f'{self.model.name}_epoch_{str(epoch)}_{\"_\".join([\"{}_{:.3f}\".format(k,v) for k,v in self.last_best_values.items()])}'\n","                self.model.save(f'{base_name}.h5')                \n","                history_df = pd.DataFrame(self.model.history.history) \n","                history_df.to_csv(f'{base_name}_history.csv',header=True, index=False)\n","                \n","                if self.colab_download:\n","                    from google.colab import files\n","                    files.download(f'{base_name}.h5')\n","                    files.download(f'{base_name}_history.csv')\n","                "],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"08mDn9XtXtIp","executionInfo":{"status":"ok","timestamp":1638745747857,"user_tz":0,"elapsed":3,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["# data extraction\n","def getE2eData13(shuffle=False):\n","    hf_Train = h5.File(f'{data_location}/e2e_Train_Data_1000.h5', 'r')\n","    hf_Test = h5.File(f'{data_location}/e2e_Test_Data_1000.h5', 'r')\n","\n","    X_train, Y_train = getNpArrayFromH5(hf_Train)\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n","    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n","\n","    if shuffle:\n","        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n","        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n","\n","    hf_Val = h5.File(f'{data_location}/e2e_Val_Data_1000.h5', 'r')\n","    X_validation, Y_validation = getNpArrayFromH5(hf_Val)\n","    Y_validation = to_categorical(Y_validation, 13)  \n","\n","    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n","\n","\n","def getE2eDataJustSecondary(shuffle=False,isColab=False):\n","    hf_Train = h5.File(f'{data_location}/e2e_Train_just_Secondary_Data_1000.h5', 'r')\n","    hf_Test = h5.File(f'{data_location}/e2e_Test_just_Secondary_Data_1000.h5', 'r')\n","\n","    X_train, Y_train = getNpArrayFromH5(hf_Train)\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    \n","    Y_train = to_categorical(Y_train, Y_test.shape[-1])  \n","    Y_test = to_categorical(Y_test, Y_test.shape[-1])  \n","\n","    if shuffle:\n","        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n","        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n","\n","    hf_Val = h5.File(f'{data_location}/e2e_Val_just_Secondary_Data_1000.h5', 'r')\n","    \n","    X_validation, Y_validation = getNpArrayFromH5(hf_Val)\n","    Y_validation = to_categorical(Y_validation, Y_test.shape[-1])  # Process the label of tain\n","\n","    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n","\n","\n","def getTest12Data():\n","    hf_Test = h5.File(f'{data_location}/e2e_Test_Data_1000_12classes.h5', 'r')\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n","    return X_test, Y_test\n","\n","\n","def get88KData():\n","    hf_Train = h5.File(f'{data_location}/e2e_Train_Data_1000_88.h5', 'r')\n","    hf_Test = h5.File(f'{data_location}/e2e_Test_Data_1000_88.h5', 'r')\n","\n","    X_train, Y_train = getNpArrayFromH5(hf_Train)\n","    X_test, Y_test = getNpArrayFromH5(hf_Test)\n","    Y_train = to_categorical(Y_train, Y_test.shape[-1])  # Process the label of tain\n","    Y_test = to_categorical(Y_test, Y_test.shape[-1])  # Process the label of te\n","\n","    hf_Val = h5.File(f'{data_location}/e2e_Val_Data_1000_88.h5', 'r') \n","    X_validation, Y_validation = getNpArrayFromH5(hf_Val)\n","    Y_validation = to_categorical(Y_validation, Y_test.shape[-1])  # Process the label of tain\n","\n","    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n","    \n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"IiA0TTr4VR2Z","executionInfo":{"status":"ok","timestamp":1638745747857,"user_tz":0,"elapsed":3,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Bidirectional\n","from tensorflow.keras.models import Model, Sequential, load_model\n","from tensorflow.keras.layers import  Dense, Flatten, Activation, Dropout, Embedding, Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, Concatenate, BatchNormalization, GaussianNoise\n","from tensorflow.keras.layers import LSTM, TimeDistributed, Permute, Reshape, Lambda, RepeatVector, Input, Multiply, SimpleRNN, GRU, LeakyReLU\n","from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n","import site\n","import pandas as pd\n","import os\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","import datetime\n","import re"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9DSXcStXi5C","executionInfo":{"status":"ok","timestamp":1638745750885,"user_tz":0,"elapsed":2608,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["X_train_1000e, Y_train_1000e, X_test_1000e, Y_test_1000e, X_val_1000e, Y_val_1000e = getE2eData13()\n","X_new_train = np.concatenate( (X_train_1000e, X_val_1000e), axis=0 )\n","Y_new_train = np.concatenate( (Y_train_1000e, Y_val_1000e), axis=0 )"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_9QxchaiSJy","executionInfo":{"status":"ok","timestamp":1638745750886,"user_tz":0,"elapsed":5,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}},"outputId":"746f9d6e-87f5-43a1-a188-6d227be8db91"},"source":["Y_val_1000e"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 1., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 1., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 1., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"UrA1SY4CHTOS"},"source":["# A basic feeder model functions to fit Test13"]},{"cell_type":"code","metadata":{"id":"UPx5iGFDo8bL","executionInfo":{"status":"ok","timestamp":1638745751653,"user_tz":0,"elapsed":2,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["def model_with_pure_rnn3():\n","    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n","    lstm_one = Bidirectional(GRU(256, return_sequences=True, kernel_initializer='RandomNormal', dropout= 0.5, recurrent_dropout = 0.5, recurrent_initializer='RandomNormal', bias_initializer='zero'))(inputs)\n","    lstm_two = Bidirectional(GRU(128, return_sequences=True, kernel_initializer='RandomNormal', dropout= 0.5, recurrent_dropout = 0.5, recurrent_initializer='RandomNormal', bias_initializer='zero'))(lstm_one)\n","    lstm_two = Bidirectional(GRU(64, return_sequences=True, kernel_initializer='RandomNormal', dropout= 0.5, recurrent_dropout = 0.5, recurrent_initializer='RandomNormal', bias_initializer='zero'))(lstm_two)\n","    attention_mul = SeqWeightedAttention()(lstm_two)\n","    attention_mul = Flatten()(attention_mul)\n","    dense_one = Dense(256, kernel_initializer='RandomNormal', bias_initializer='zeros', activation='relu', name=\"antepenultimate_dense\")(attention_mul)\n","    dense_one = Dropout(0.5)(dense_one)\n","    dense_two = Dense(128, kernel_initializer='RandomNormal', bias_initializer='zeros', activation='relu', name=\"penultimate_dense\")(dense_one)\n","    dense_two = Dropout(0.4)(dense_two)\n","    dense_three = Dense(64, kernel_initializer='RandomNormal', bias_initializer='zeros', activation='relu', name=\"last_dense\")(dense_two)\n","    dense_three = Dropout(0.3)(dense_two)\n","    output = Dense(13, activation='softmax', name=\"last_softmax\")(dense_three)\n","    model = Model([inputs], output, name=\"pure_rnn3\")\n","    return model\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHdJJrIbn3DR","executionInfo":{"status":"ok","timestamp":1638745751972,"user_tz":0,"elapsed":4,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["def baseline_CNN_finalist_128(model_name, inshape, num_classes = 13):\n","\n","    model = tf.keras.Sequential()\n","\n","    model.add(tf.keras.layers.Conv1D(128 ,10 ,padding='same' ,input_shape=inshape))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(2))\n","\n","    model.add(tf.keras.layers.GaussianNoise(1))\n","    model.add(tf.keras.layers.Dropout(rate=0.5))\n","\n","    model.add(tf.keras.layers.Conv1D(128 ,10 ,padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(4))\n","\n","    model.add(tf.keras.layers.GaussianNoise(1))\n","    model.add(tf.keras.layers.Dropout(rate=0.5))\n","\n","    model.add(tf.keras.layers.Conv1D(256 ,10 ,padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(2))\n","\n","    model.add(tf.keras.layers.Conv1D(256 ,10 ,padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(4))\n","\n","    model.add(tf.keras.layers.GaussianNoise(1))\n","    model.add(tf.keras.layers.Dropout(rate=0.5))\n","\n","    model.add(tf.keras.layers.Conv1D(256 ,10 ,padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(4))\n","\n","    model.add(tf.keras.layers.GaussianNoise(1))\n","    model.add(tf.keras.layers.Dropout(rate=0.5))\n","\n","    model.add(tf.keras.layers.Flatten())\n","\n","    model.add(tf.keras.layers.Dense(128))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","\n","    model.add(tf.keras.layers.Dense(64))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","\n","    model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n","    model._name = model_name\n","\n","    return model\n","\n","def baseline_CNN_finalist_256(model_name, inshape, num_classes = 13):\n","\n","    model = tf.keras.Sequential()\n","\n","    model.add(tf.keras.layers.Conv1D(256 ,10 ,padding='same' ,input_shape=inshape))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(2))\n","\n","    model.add(tf.keras.layers.GaussianNoise(1))\n","    model.add(tf.keras.layers.Dropout(rate=0.5))\n","\n","    model.add(tf.keras.layers.Conv1D(256 ,10 ,padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(4))\n","\n","    model.add(tf.keras.layers.GaussianNoise(1))\n","    model.add(tf.keras.layers.Dropout(rate=0.5))\n","\n","    model.add(tf.keras.layers.Conv1D(256 ,10 ,padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(2))\n","\n","    model.add(tf.keras.layers.Conv1D(256 ,10 ,padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(4))\n","\n","    model.add(tf.keras.layers.GaussianNoise(1))\n","    model.add(tf.keras.layers.Dropout(rate=0.5))\n","\n","    model.add(tf.keras.layers.Conv1D(256 ,10 ,padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","    model.add(tf.keras.layers.MaxPooling1D(4))\n","\n","    model.add(tf.keras.layers.GaussianNoise(1))\n","    model.add(tf.keras.layers.Dropout(rate=0.5))\n","\n","    model.add(tf.keras.layers.Flatten())\n","\n","    model.add(tf.keras.layers.Dense(128))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","\n","    model.add(tf.keras.layers.Dense(64))\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n","\n","    model.add(tf.keras.layers.Dense(num_classes, activation=tf.nn.softmax))\n","    model._name = model_name\n","\n","    return model\n","\n","def model_with_pure_rnn_finalist(model_name, input_shape = (1000, 8,),num_classes = 13):\n","\n","    # RNN part\n","    inputs = Input(shape=input_shape)\n","    lstm_one = Bidirectional \\\n","        (GRU(256, return_sequences=True, kernel_initializer='RandomNormal', dropout= 0.5, recurrent_dropout = 0.5, recurrent_initializer='RandomNormal', bias_initializer='zero'))(inputs)\n","    lstm_two = Bidirectional \\\n","        (GRU(128, return_sequences=True, kernel_initializer='RandomNormal', dropout= 0.5, recurrent_dropout = 0.5, recurrent_initializer='RandomNormal', bias_initializer='zero'))(lstm_one)\n","    attention = SeqWeightedAttention()(lstm_two)\n","    attention = Flatten()(attention)\n","    rnnoutput = Dense(256 ,kernel_initializer='RandomNormal', bias_initializer='zeros')(attention)\n","    rnnoutput = BatchNormalization()(rnnoutput)\n","    rnnoutput = GaussianNoise(1)(rnnoutput)\n","    rnnoutput = Dropout(0.4)(rnnoutput)\n","\n","    # Dense Feed-forward\n","    dense_one = Dense(128, kernel_initializer='RandomNormal', bias_initializer='zeros')(rnnoutput)\n","    dense_one = LeakyReLU()(dense_one)\n","    dense_one = Dropout(0.5)(dense_one)\n","    dense_one = BatchNormalization()(dense_one)\n","    dense_two = Dense(64, kernel_initializer='RandomNormal', bias_initializer='zeros')(dense_one)\n","    dense_two = LeakyReLU()(dense_two)\n","    dense_two = Dropout(0.4)(dense_two)\n","\n","    # Output\n","    output = Dense(num_classes, activation='softmax')(dense_two)\n","    model = Model([inputs], output, name = model_name)\n","    return model\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"-SIFXm1g9t7Z","executionInfo":{"status":"ok","timestamp":1638745751972,"user_tz":0,"elapsed":3,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}}},"source":["\n","\n","def model_combination(model_name, input_shape,num_classes = 13):\n","    model = Sequential([\n","        tf.keras.Input(shape=input_shape),\n","        BatchNormalization(),\n","        Dense(256, kernel_initializer='RandomNormal', bias_initializer='zeros'),\n","        LeakyReLU(),\n","        Dropout(0.6),\n","        Dense(128, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-3)),\n","        LeakyReLU(),\n","        Dropout(0.6),\n","        Dense(32, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-2)),\n","        LeakyReLU(),\n","        Dropout(0.5),\n","        Dense(num_classes, activation='softmax')\n","    ], name=model_name)\n","    return model\n","\n","\n","def compile_and_fit_model_basic_core(  model_func,\n","                                  model_name,\n","                                  input_shape,\n","                                  X_train,\n","                                  Y_train,\n","                                  save_max_epoch=True,\n","                                  save_final=False,\n","                                  patience_count = None,\n","                                  early_stopping_obs = 'val_sparse_categorical_accuracy',\n","                                  log_history = True,\n","                                  verbose_level = 0,\n","                                  use_tb_callback = False,\n","                                  **kwargs):\n","    m = None\n","    if isinstance(model_func, tf.keras.models.Model):\n","        m = model_func\n","        m._name = model_name\n","    else:\n","        m = model_func(model_name, input_shape)\n","\n","\n","    if 'validation_data' not in kwargs.keys() and 'val_' in early_stopping_obs:\n","        early_stopping_obs = early_stopping_obs.replace('val_','')\n","\n","    callbacks_used = []\n","    if save_max_epoch:\n","      callbacks_used.append(ModelCheckpoint(f'/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/{m.name}' + '_model_ep{epoch:03d}_{accuracy:0.3f}_{val_accuracy:0.3f}',\n","                                            save_weights_only=False,\n","                                            monitor = early_stopping_obs,\n","                                            mode='max',\n","                                            save_best_only=True))\n","\n","    if use_tb_callback:  \n","      tb_callback = TensorBoard(log_dir=f'/content/drive/MyDrive/data_papers/{paper_name}/model_tb/{m.name}_logs', histogram_freq=kwargs.pop(\"histogram_freq\", 1))\n","      # if save_every_epoch:\n","      #     tb_callback.append(ModelCheckpoint(f'{m.name}' + '_model_{epoch:03d}_{val_accuracy:0.2f}'))\n","\n","    if patience_count is not None:\n","      callbacks_used.append(tf.keras.callbacks.EarlyStopping(monitor=early_stopping_obs, patience=patience_count))\n","\n","    if log_history:\n","        callbacks_used.append(tf.keras.callbacks.CSVLogger(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_history/history_log_{model_name}_{datetime.date.today().strftime('%Y%m%d')}.csv\", append=True))\n","\n","    m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    history = m.fit(X_train, Y_train, callbacks=callbacks_used, verbose=verbose_level, **kwargs)\n","    if save_final:\n","        make_dir_if_not_exist(model_name)\n","        m.save(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_finals/{m.name}_saved_model_after_fit\")  # Save the model\n","        \n","    return (m, history)\n","\n"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q6M9xK1N-i9t"},"source":["# Set up the RNN models for reuse on Test13"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WvqTW_8Vq9ps","executionInfo":{"status":"ok","timestamp":1638745804864,"user_tz":0,"elapsed":16438,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}},"outputId":"91d36c63-ec31-4f26-b5f5-f05691736a50"},"source":["# rnn_base = load_model(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/RNN_A_102_20211203065818_model_ep044_0.900_0.965\")\n","\n","# rnn_base = load_model(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/RNN_A_201_20211204013934_model_ep080_0.949_1.000\")\n","\n","# rnn_base = load_model(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/RNN_A_401_20211205025618_model_ep034_0.843_0.932\")\n","\n","rnn_base = load_model(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/RNN_A_402_20211205185555_model_ep011_0.600_0.681\")\n"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrHUZF0asisF","executionInfo":{"status":"ok","timestamp":1638799206397,"user_tz":0,"elapsed":53304269,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}},"outputId":"0496eba9-7229-49d2-ee99-bbe39465c035"},"source":[" m1xy, h1xy = compile_and_fit_model_basic_core( rnn_base,  \n","                    rnn_base.name, \n","                    X_new_train[0].shape, \n","                    X_new_train, \n","                    Y_new_train,\n","                    save_max_epoch=True,\n","                    save_final=True,\n","                    patience_count = 8,\n","                    early_stopping_obs = 'val_accuracy',\n","                    log_history = True,                             \n","                    batch_size=64, \n","                    epochs=100, \n","                    class_weight=None, \n","                    verbose_level=1,\n","                    validation_data=(X_val_1000e, Y_val_1000e))"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","121/121 [==============================] - ETA: 0s - loss: 1.1403 - accuracy: 0.6139 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep001_0.614_0.723/assets\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1409s 12s/step - loss: 1.1403 - accuracy: 0.6139 - val_loss: 0.7407 - val_accuracy: 0.7235\n","Epoch 2/100\n","121/121 [==============================] - 1361s 11s/step - loss: 1.0510 - accuracy: 0.6388 - val_loss: 0.8509 - val_accuracy: 0.6884\n","Epoch 3/100\n","121/121 [==============================] - ETA: 0s - loss: 1.0123 - accuracy: 0.6551 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep003_0.655_0.753/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep003_0.655_0.753/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1369s 11s/step - loss: 1.0123 - accuracy: 0.6551 - val_loss: 0.6938 - val_accuracy: 0.7526\n","Epoch 4/100\n","121/121 [==============================] - 1387s 11s/step - loss: 1.0286 - accuracy: 0.6587 - val_loss: 0.9373 - val_accuracy: 0.6779\n","Epoch 5/100\n","121/121 [==============================] - 1419s 12s/step - loss: 0.9889 - accuracy: 0.6651 - val_loss: 0.6966 - val_accuracy: 0.7468\n","Epoch 6/100\n","121/121 [==============================] - 1435s 12s/step - loss: 0.9886 - accuracy: 0.6655 - val_loss: 0.8995 - val_accuracy: 0.6698\n","Epoch 7/100\n","121/121 [==============================] - 1436s 12s/step - loss: 0.9058 - accuracy: 0.6960 - val_loss: 0.9048 - val_accuracy: 0.6546\n","Epoch 8/100\n","121/121 [==============================] - ETA: 0s - loss: 0.8637 - accuracy: 0.7059 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep008_0.706_0.785/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep008_0.706_0.785/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1432s 12s/step - loss: 0.8637 - accuracy: 0.7059 - val_loss: 0.5853 - val_accuracy: 0.7853\n","Epoch 9/100\n","121/121 [==============================] - ETA: 0s - loss: 0.8256 - accuracy: 0.7148 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep009_0.715_0.797/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep009_0.715_0.797/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1441s 12s/step - loss: 0.8256 - accuracy: 0.7148 - val_loss: 0.5571 - val_accuracy: 0.7970\n","Epoch 10/100\n","121/121 [==============================] - 1411s 12s/step - loss: 0.7974 - accuracy: 0.7339 - val_loss: 0.5997 - val_accuracy: 0.7876\n","Epoch 11/100\n","121/121 [==============================] - 1402s 12s/step - loss: 0.7684 - accuracy: 0.7413 - val_loss: 0.7240 - val_accuracy: 0.7398\n","Epoch 12/100\n","121/121 [==============================] - 1391s 11s/step - loss: 0.7427 - accuracy: 0.7493 - val_loss: 0.5575 - val_accuracy: 0.7853\n","Epoch 13/100\n","121/121 [==============================] - ETA: 0s - loss: 0.7307 - accuracy: 0.7533 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep013_0.753_0.805/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep013_0.753_0.805/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1420s 12s/step - loss: 0.7307 - accuracy: 0.7533 - val_loss: 0.5051 - val_accuracy: 0.8051\n","Epoch 14/100\n","121/121 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.7710 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep014_0.771_0.825/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep014_0.771_0.825/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1410s 12s/step - loss: 0.6871 - accuracy: 0.7710 - val_loss: 0.4832 - val_accuracy: 0.8250\n","Epoch 15/100\n","121/121 [==============================] - ETA: 0s - loss: 0.6645 - accuracy: 0.7762 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep015_0.776_0.834/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep015_0.776_0.834/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1410s 12s/step - loss: 0.6645 - accuracy: 0.7762 - val_loss: 0.4330 - val_accuracy: 0.8343\n","Epoch 16/100\n","121/121 [==============================] - ETA: 0s - loss: 0.6330 - accuracy: 0.7905 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep016_0.791_0.858/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep016_0.791_0.858/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1436s 12s/step - loss: 0.6330 - accuracy: 0.7905 - val_loss: 0.3944 - val_accuracy: 0.8576\n","Epoch 17/100\n","121/121 [==============================] - 1447s 12s/step - loss: 0.6104 - accuracy: 0.7966 - val_loss: 0.4818 - val_accuracy: 0.8203\n","Epoch 18/100\n","121/121 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.7966 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep018_0.797_0.894/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep018_0.797_0.894/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1467s 12s/step - loss: 0.6138 - accuracy: 0.7966 - val_loss: 0.3060 - val_accuracy: 0.8938\n","Epoch 19/100\n","121/121 [==============================] - 1413s 12s/step - loss: 0.5981 - accuracy: 0.8022 - val_loss: 0.3460 - val_accuracy: 0.8751\n","Epoch 20/100\n","121/121 [==============================] - 1431s 12s/step - loss: 0.5482 - accuracy: 0.8185 - val_loss: 0.3761 - val_accuracy: 0.8635\n","Epoch 21/100\n","121/121 [==============================] - 1447s 12s/step - loss: 0.5388 - accuracy: 0.8255 - val_loss: 0.4033 - val_accuracy: 0.8670\n","Epoch 22/100\n","121/121 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.8280 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep022_0.828_0.900/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep022_0.828_0.900/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1475s 12s/step - loss: 0.5448 - accuracy: 0.8280 - val_loss: 0.2647 - val_accuracy: 0.8996\n","Epoch 23/100\n","121/121 [==============================] - 1442s 12s/step - loss: 0.5203 - accuracy: 0.8303 - val_loss: 0.3122 - val_accuracy: 0.8798\n","Epoch 24/100\n","121/121 [==============================] - 1454s 12s/step - loss: 0.4897 - accuracy: 0.8432 - val_loss: 0.2826 - val_accuracy: 0.8891\n","Epoch 25/100\n","121/121 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.8452 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep025_0.845_0.914/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep025_0.845_0.914/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1469s 12s/step - loss: 0.4756 - accuracy: 0.8452 - val_loss: 0.2494 - val_accuracy: 0.9137\n","Epoch 26/100\n","121/121 [==============================] - 1456s 12s/step - loss: 0.4572 - accuracy: 0.8550 - val_loss: 0.3081 - val_accuracy: 0.8845\n","Epoch 27/100\n","121/121 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.8572 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep027_0.857_0.917/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep027_0.857_0.917/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1473s 12s/step - loss: 0.4529 - accuracy: 0.8572 - val_loss: 0.2236 - val_accuracy: 0.9172\n","Epoch 28/100\n","121/121 [==============================] - 1460s 12s/step - loss: 0.4231 - accuracy: 0.8682 - val_loss: 0.4019 - val_accuracy: 0.8553\n","Epoch 29/100\n","121/121 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.8581 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep029_0.858_0.937/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_402_20211205185555_model_ep029_0.858_0.937/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1490s 12s/step - loss: 0.4352 - accuracy: 0.8581 - val_loss: 0.1852 - val_accuracy: 0.9370\n","Epoch 30/100\n","121/121 [==============================] - 1485s 12s/step - loss: 0.4194 - accuracy: 0.8643 - val_loss: 0.2033 - val_accuracy: 0.9312\n","Epoch 31/100\n","121/121 [==============================] - 1488s 12s/step - loss: 0.4128 - accuracy: 0.8680 - val_loss: 0.1891 - val_accuracy: 0.9207\n","Epoch 32/100\n","121/121 [==============================] - 1488s 12s/step - loss: 0.4046 - accuracy: 0.8671 - val_loss: 0.1825 - val_accuracy: 0.9335\n","Epoch 33/100\n","121/121 [==============================] - 1464s 12s/step - loss: 0.3983 - accuracy: 0.8736 - val_loss: 0.2139 - val_accuracy: 0.9277\n","Epoch 34/100\n","121/121 [==============================] - 1466s 12s/step - loss: 0.3708 - accuracy: 0.8831 - val_loss: 0.1874 - val_accuracy: 0.9230\n","Epoch 35/100\n","121/121 [==============================] - 1464s 12s/step - loss: 0.3887 - accuracy: 0.8760 - val_loss: 0.1909 - val_accuracy: 0.9335\n","Epoch 36/100\n","121/121 [==============================] - 1474s 12s/step - loss: 0.3631 - accuracy: 0.8826 - val_loss: 0.1797 - val_accuracy: 0.9370\n","Epoch 37/100\n","121/121 [==============================] - 1462s 12s/step - loss: 0.3395 - accuracy: 0.8902 - val_loss: 0.1869 - val_accuracy: 0.9300\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_finals/RNN_A_402_20211205185555_saved_model_after_fit/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_finals/RNN_A_402_20211205185555_saved_model_after_fit/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2326710> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22b2310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b22422d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f18b2242d50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}]},{"cell_type":"code","metadata":{"id":"xLhMrCbjcT1h"},"source":["# rnn_base = load_model(f\"/content/drive/MyDrive/data_papers/{paper_name}/model_checkpoints/RNN_A_102_20211203065818_model_ep033_0.854_0.926\")\n","# rnn_base._name = rnn_base._name.replace(\"_102_\",\"_102B_\")\n","# m1x2, h1x2 = compile_and_fit_model_basic_core( rnn_base,  \n","#                     rnn_base.name, \n","#                     X_new_train[0].shape, \n","#                     X_new_train, \n","#                     Y_new_train,\n","#                     save_max_epoch=True,\n","#                     save_final=True,\n","#                     patience_count = 4,\n","#                     early_stopping_obs = 'val_accuracy',\n","#                     log_history = True,                             \n","#                     batch_size=64, \n","#                     epochs=30, \n","#                     class_weight=None, \n","#                     verbose_level=1,\n","#                     validation_data=(X_val_1000e, Y_val_1000e))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBq9lCju-i9t","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1638809198666,"user_tz":0,"elapsed":9989753,"user":{"displayName":"Hans Roggeman","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10574434403170915342"}},"outputId":"d76c7272-2c8c-4dbc-f3b2-c8e46c89ee39"},"source":["# # saving 100 DNNs\n","for model_count in [i+1 for i in range(10)]:\n","  m1, h1 = compile_and_fit_model_basic_core( model_with_pure_rnn_finalist,  \n","                    f\"RNN_A_{str(model_count+403)}_{datetime.datetime.now():%Y%m%d%H%M%S}\", \n","                    X_new_train[0].shape, \n","                    X_new_train, \n","                    Y_new_train,\n","                    save_max_epoch=True,\n","                    save_final=True,\n","                    patience_count = 20,\n","                    early_stopping_obs = 'val_accuracy',\n","                    log_history = True,                             \n","                    batch_size=64, \n","                    epochs=250, \n","                    class_weight=None, \n","                    verbose_level=1,\n","                    validation_data=(X_val_1000e, Y_val_1000e))"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/250\n","121/121 [==============================] - ETA: 0s - loss: 2.3317 - accuracy: 0.1874 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep001_0.187_0.100/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep001_0.187_0.100/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e5c9d290> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e332efd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e1c07850> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e43af590> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1494s 12s/step - loss: 2.3317 - accuracy: 0.1874 - val_loss: 2.4592 - val_accuracy: 0.1004\n","Epoch 2/250\n","121/121 [==============================] - ETA: 0s - loss: 2.0672 - accuracy: 0.2699 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep002_0.270_0.179/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep002_0.270_0.179/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e5c9d290> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e332efd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e1c07850> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e43af590> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1495s 12s/step - loss: 2.0672 - accuracy: 0.2699 - val_loss: 2.2070 - val_accuracy: 0.1785\n","Epoch 3/250\n","121/121 [==============================] - 1498s 12s/step - loss: 1.9256 - accuracy: 0.3252 - val_loss: 3.6368 - val_accuracy: 0.1039\n","Epoch 4/250\n","121/121 [==============================] - ETA: 0s - loss: 1.7661 - accuracy: 0.3826 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep004_0.383_0.180/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep004_0.383_0.180/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e5c9d290> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e332efd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e1c07850> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e43af590> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1527s 13s/step - loss: 1.7661 - accuracy: 0.3826 - val_loss: 3.4455 - val_accuracy: 0.1797\n","Epoch 5/250\n","121/121 [==============================] - ETA: 0s - loss: 1.6313 - accuracy: 0.4276 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep005_0.428_0.445/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep005_0.428_0.445/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e5c9d290> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e332efd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e1c07850> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e43af590> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1522s 13s/step - loss: 1.6313 - accuracy: 0.4276 - val_loss: 1.6778 - val_accuracy: 0.4446\n","Epoch 6/250\n","121/121 [==============================] - ETA: 0s - loss: 1.5022 - accuracy: 0.4802 INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep006_0.480_0.575/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/data_papers/test13/model_checkpoints/RNN_A_403_20211206140009_model_ep006_0.480_0.575/assets\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e5c9d290> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e332efd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e1c07850> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f14e43af590> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/121 [==============================] - 1523s 13s/step - loss: 1.5022 - accuracy: 0.4802 - val_loss: 1.1770 - val_accuracy: 0.5753\n","Epoch 7/250\n"," 75/121 [=================>............] - ETA: 9:22 - loss: 1.4111 - accuracy: 0.5069"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-d0cfc589c977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mverbose_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     validation_data=(X_val_1000e, Y_val_1000e))\n\u001b[0m","\u001b[0;32m<ipython-input-25-1992fb863201>\u001b[0m in \u001b[0;36mcompile_and_fit_model_basic_core\u001b[0;34m(model_func, model_name, input_shape, X_train, Y_train, save_max_epoch, save_final, patience_count, early_stopping_obs, log_history, verbose_level, use_tb_callback, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_used\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_final\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mmake_dir_if_not_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}